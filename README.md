# TASK-2

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: SONIYA D

*INTERN ID*: CT04DR2644

*DOMAIN*: DATA SCIENCE

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTHOSH

##Task–2 of the CodTech Data Science Internship was focused on understanding and implementing a Deep Learning project using Python. The main objective of this task was to design, train, and evaluate a deep learning model capable of solving a real-world problem. Deep learning is an important branch of machine learning that uses neural networks with multiple layers to automatically learn patterns from large and complex datasets. This task helped me gain practical exposure to deep learning concepts and their implementation using modern libraries.
For this task, I worked on an image classification problem using the TensorFlow deep learning framework. TensorFlow provides a high-level API known as Keras, which makes it easier to build, train, and evaluate neural network models. A standard image dataset was used, which allowed me to focus on model development rather than data collection. Image classification is a common and widely used application of deep learning, making it an ideal choice for this task.
The first step in this project was data loading and preprocessing. The dataset consisted of grayscale images and their corresponding labels. Before feeding the data into the neural network, preprocessing steps such as normalization were applied. Normalization scales the pixel values to a fixed range, which helps improve training speed and model accuracy. Proper preprocessing is essential in deep learning because neural networks are sensitive to the scale and quality of input data.
The next stage involved building the deep learning model. A neural network architecture was created using multiple layers, including an input layer, hidden layers, and an output layer. Dense layers with appropriate activation functions were used to enable the model to learn non-linear relationships within the data. The output layer used a Softmax activation function to classify the input images into different categories. This architecture allowed the model to effectively extract features from the image data and make accurate predictions.
After building the model, it was compiled using an optimizer, a loss function, and evaluation metrics. The optimizer helped adjust the model weights during training, while the loss function measured the difference between predicted and actual values. Accuracy was used as the primary evaluation metric to assess the model’s performance. The model was then trained using the training dataset for multiple epochs. During training, the model gradually improved its performance by learning from errors and updating its parameters.
Once training was completed, the model was evaluated on a separate test dataset to measure its generalization ability. The evaluation results provided insight into how well the model could classify unseen images. Additionally, the training and validation accuracy were visualized using graphs. These visualizations helped in understanding the learning behavior of the model and identifying potential issues such as overfitting or underfitting.
Through this task, I gained valuable hands-on experience with deep learning workflows, including data preprocessing, model design, training, evaluation, and visualization. I also developed a better understanding of how neural networks learn from data and how deep learning techniques can be applied to solve complex problems. Overall, Task–2 significantly enhanced my practical knowledge of deep learning and strengthened my confidence in working with advanced machine learning models.
